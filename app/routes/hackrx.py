from fastapi import APIRouter, HTTPException, Depends
from pydantic import BaseModel
from typing import List
import aiohttp
import os
import json
from starlette.datastructures import UploadFile as StarletteUploadFile
import tempfile
from app.services.document_loader import load_document
from app.services.chunker import chunk_text
from app.services.embedder import embed_chunks
from app.services.query_service import query_documents_batch
from app.auth.token_auth import verify_token
from app.routes.indexmaker import generate_namespace_index
import io

router = APIRouter()

# === Path to persistent mapping file ===
MAP_FILE_PATH = "ufiles.json"

# === Load mapping from JSON file ===
def load_document_map():
    if os.path.exists(MAP_FILE_PATH):
        with open(MAP_FILE_PATH, "r") as f:
            return json.load(f)
    return {}

# === Save updated mapping back to JSON ===
def save_document_map(document_map):
    with open(MAP_FILE_PATH, "w") as f:
        json.dump(document_map, f, indent=2)

# Load map at startup
document_namespace_map = load_document_map()

class HackRxRequest(BaseModel):
    documents: str  # PDF URL
    questions: List[str]

@router.post("/run", dependencies=[Depends(verify_token)])
async def process_and_query(request: HackRxRequest):
    document_url = request.documents

    try:
        # ‚úÖ If URL already exists in map
        if document_url in document_namespace_map:
            namespace = document_namespace_map[document_url]
            print(f"‚úÖ Found document in map. Using namespace: {namespace}")
            answers = await query_documents_batch(request.questions, namespace=namespace)
            return {"answers": answers}

        # üÜï New document: embed and index
        namespace = generate_namespace_index()
        print(f"üÜï New document detected. Generated namespace: {namespace}")

        async with aiohttp.ClientSession() as session:
            async with session.get(document_url) as resp:
                if resp.status != 200:
                    raise HTTPException(status_code=400, detail="Failed to download document")
                document_bytes = await resp.read()

        # üßæ Extract text
        filename = os.path.basename(document_url)
        upload_file = StarletteUploadFile(filename=filename, file=io.BytesIO(document_bytes))

        if "hackrx.in/utils/get-secret-token" in document_url:
            token = await load_document(document_url)
            ans = "The secret token is: " + token
            return {"answers": ans}
        
        text = await load_document(document_url)
        if not text.strip():
            raise HTTPException(status_code=400, detail="Extracted document is empty.")
        
        # ‚úÇÔ∏è Chunk and embed
        chunks = chunk_text(text)
        await embed_chunks(chunks=chunks, np=namespace)

        # üíæ Update and persist map
        document_namespace_map[document_url] = namespace
        save_document_map(document_namespace_map)

        # üîç Query
        answers = await query_documents_batch(request.questions, namespace=namespace)
        return {"answers": answers}

    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Processing error: {str(e)}")
